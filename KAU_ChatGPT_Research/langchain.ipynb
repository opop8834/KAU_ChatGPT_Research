{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import json\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, FAISS, LanceDB\n",
    "sys.path.append(\"C:/Users/gka30/Desktop/langchain\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open ai\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "os.environ['OPENAI_API_KEY'] = 'API_KEY'\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "emb = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)87a7d/.gitattributes: 100%|██████████| 1.52k/1.52k [00:00<?, ?B/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 191/191 [00:00<00:00, 149kB/s]\n",
      "Downloading (…)625eb87a7d/README.md: 100%|██████████| 89.1k/89.1k [00:00<?, ?B/s]\n",
      "Downloading (…)5eb87a7d/config.json: 100%|██████████| 779/779 [00:00<?, ?B/s] \n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 124/124 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.34G/1.34G [00:25<00:00, 53.3MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 52.0/52.0 [00:00<?, ?B/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 125/125 [00:00<?, ?B/s] \n",
      "Downloading (…)87a7d/tokenizer.json: 100%|██████████| 711k/711k [00:00<00:00, 53.8MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 366/366 [00:00<?, ?B/s] \n",
      "Downloading (…)625eb87a7d/vocab.txt: 100%|██████████| 232k/232k [00:00<?, ?B/s]\n",
      "Downloading (…)eb87a7d/modules.json: 100%|██████████| 349/349 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "# hugging face\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Chroma db에서는 dimension 이슈 발생\n",
    "emb = HuggingFaceEmbeddings(model_name = 'BAAI/bge-large-en-v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# LLAMA - need to wait the authorization\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "emb = LlamaCppEmbeddings(model_path=\"C:/Users/gka30/Desktop/langchain/llama-2-7b-vietnamese-20k.Q5_K_M.gguf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palm\n",
    "from langchain.embeddings import VertexAIEmbeddings, GooglePalmEmbeddings\n",
    "import google.generativeai as palm\n",
    "os.environ[\"PALM_API_KEY\"] = 'API_KEY'\n",
    "palm.api_key = os.getenv(\"PALM_API_KEY\")\n",
    "\n",
    "palm_emb = GooglePalmEmbeddings()\n",
    "vertex_emb = VertexAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_kor = None\n",
    "\n",
    "def initialize_vectordb_kor():\n",
    "    global vectordb_kor\n",
    "    \n",
    "    loaders = [\n",
    "        CSVLoader(\"C:/Users/gka30/Desktop/langchain/Korean_data.csv\", encoding='UTF-8')\n",
    "    ]\n",
    "    docs = []\n",
    "    for loader in loaders:\n",
    "        docs.extend(loader.load())\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1500,\n",
    "        chunk_overlap = 150\n",
    "    )\n",
    "    documnent = text_splitter.split_documents(docs)\n",
    "    \n",
    "    persist_directory = 'docs/chroma/'\n",
    "\n",
    "    vectordb_kor = Chroma.from_documents(\n",
    "        documents=documnent,\n",
    "        embedding=emb,\n",
    "        # persist_directory=persist_directory\n",
    "    )\n",
    "\n",
    "    # vectordb = FAISS.from_documents(\n",
    "    #     documents=documnent,\n",
    "    #     embedding=hug_emb,\n",
    "    #     # persist_directory=persist_directory\n",
    "    # )\n",
    "\n",
    "    # vectordb = LanceDB.from_documents(\n",
    "    #     documents=documnent,\n",
    "    #     embedding=hug_emb,\n",
    "    #     persist_directory=persist_directory\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb_eng = None\n",
    "\n",
    "def initialize_vectordb_eng():\n",
    "    global vectordb_eng\n",
    "    \n",
    "    loaders = [\n",
    "        CSVLoader(\"C:/Users/gka30/Desktop/langchain/English_data.csv\", encoding='UTF-8')\n",
    "    ]\n",
    "    docs = []\n",
    "    for loader in loaders:\n",
    "        docs.extend(loader.load())\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 1500,\n",
    "        chunk_overlap = 150\n",
    "    )\n",
    "    documnent = text_splitter.split_documents(docs)\n",
    "    \n",
    "    persist_directory = 'docs/chroma/'\n",
    "\n",
    "    vectordb_eng = Chroma.from_documents(\n",
    "        documents=documnent,\n",
    "        embedding=emb,\n",
    "        # persist_directory=persist_directory\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectordb_kor is None:\n",
    "   initialize_vectordb_kor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vectordb_eng is None:\n",
    "   initialize_vectordb_eng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchainTest_kor(request):\n",
    "    global vectordb_kor\n",
    "    # data = json.loads(request.body.decode(\"utf-8\"))\n",
    "    # question = data[\"messages\"][0][\"content\"]\n",
    "\n",
    "    docs = vectordb_kor.similarity_search(request, k=3)\n",
    "    response_content = docs[0].page_content\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"지금부터 주는 정보는 한국항공대학교에 대한 정보야\"\n",
    "                f\"내가 준 기반 정보를 바탕으로만 대답해.\"\n",
    "                f\"기반 정보: {response_content} / \"\n",
    "                f\"내 질문: {request}\"\n",
    "            )\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    gpt_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    return gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchainTest_eng(request):\n",
    "    global vectordb_eng\n",
    "    # data = json.loads(request.body.decode(\"utf-8\"))\n",
    "    # question = data[\"messages\"][0][\"content\"]\n",
    "    \n",
    "    docs = vectordb_eng.similarity_search(request, k=3)\n",
    "    response_content = docs[0].page_content\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "                f\"This is the Korea AeroSpace University Information.\"\n",
    "                f\"Answer the question base on the information which I gave.\"\n",
    "                f\"Based Information: {response_content} / \"\n",
    "                f\"Answer: {request}\"\n",
    "            )\n",
    "        }]\n",
    "    )\n",
    "            \n",
    "    gpt_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    return gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'복수전공 신청 대상자는 한국항공대학교의 1학년 과정 이상을 수료한 재학생입니다.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchainTest_kor('복수전공 신청 대상자는 누구인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The applicants for a double major are current students who have completed at least the first year of the program at Korea AeroSpace University.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchainTest_eng('Who are the applicants for a double major?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "복수전공 신청 기간은 매학기 소정 기간 내에 가능합니다. 1학기는 1월 중, 2학기는 7월 중에 신청하실 수 있습니다. 따라서 현재 학기에 복수전공을 신청하려면 1월 중에 신청하셔야 합니다. 자세한 일정은 학사공지의 개별 공지사항을 참고하시면 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(langchainTest_kor('복수전공 신청 기간은 언제인가요?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The application period for a double major is within the prescribed period each semester. Students can apply in January for the first semester and in July for the second semester.\n"
     ]
    }
   ],
   "source": [
    "print(langchainTest_eng('When is the application period for a double major?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'전과 신청을 위해 제출해야 하는 서류는 학기재수 신청원 양식입니다. 추가적인 정보나 문의 사항은 교무팀의 김민경님에게 전화번호 02-300-0457로 문의하거나 이메일 kyomu@kau.ac.kr로 문의하시면 됩니다.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchainTest_kor('전과 신청을 위해 제출해야 하는 서류는 무엇인가요?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the information provided, there is no specific mention of submitting documents for a criminal history application. Therefore, it is unclear what documents are required for a criminal history application at Korea AeroSpace University. It is advised to consult the university's academic system or contact the relevant department for more information on the required documents for a criminal history application.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchainTest_eng('What documents do I need to submit for a criminal history application?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
